---
# ----------------------------------------------------------------------------
#
#     ***     AUTO GENERATED CODE    ***    Type: MMv1     ***
#
# ----------------------------------------------------------------------------
#
#     This file is automatically generated by Magic Modules and manual
#     changes will be clobbered when the file is regenerated.
#
#     Please read more about how to change this file in
#     .github/CONTRIBUTING.md.
#
# ----------------------------------------------------------------------------
subcategory: "Vertex AI"
page_title: "Google: google_vertex_ai_model_deployment"
description: |-
  A deployment of a Model.
---

# google\_vertex\_ai\_model\_deployment

A deployment of a Model. Endpoints contain one or more DeployedModels.


To get more information about ModelDeployment, see:

* [API documentation](https://cloud.google.com/vertex-ai/docs/reference/rest/v1beta1/projects.locations.endpoints#DeployedModel)
* How-to Guides
    * [Official Documentation](https://cloud.google.com/vertex-ai/docs)

<div class = "oics-button" style="float: right; margin: 0 0 -15px">
  <a href="https://console.cloud.google.com/cloudshell/open?cloudshell_git_repo=https%3A%2F%2Fgithub.com%2Fterraform-google-modules%2Fdocs-examples.git&cloudshell_working_dir=vertex_ai_model_deployment&cloudshell_image=gcr.io%2Fgraphite-cloud-shell-images%2Fterraform%3Alatest&open_in_editor=main.tf&cloudshell_print=.%2Fmotd&cloudshell_tutorial=.%2Ftutorial.md" target="_blank">
    <img alt="Open in Cloud Shell" src="//gstatic.com/cloudssh/images/open-btn.svg" style="max-height: 44px; margin: 32px auto; max-width: 100%;">
  </a>
</div>
## Example Usage - Vertex Ai Model Deployment


```hcl
resource "google_vertex_ai_model_deployment" "model_deployment" {
  dedicated_resources {
    machine_spec {
      machine_type = "n1-standard-2"
    }
    min_replica_count = 1
    max_replica_count = 1
  }
  endpoint = "${google_vertex_ai_endpoint.minimal.name}"
  model    = "${google_vertex_ai_model.minimal.id}"
  location = "us-central1"
}

resource "google_vertex_ai_model" "minimal" {
  container_spec {
    image_uri = "us-docker.pkg.dev/vertex-ai/prediction/xgboost-cpu.1-5:latest"
  }
  display_name = "sample-model"
  location     = "us-central1"
  artifact_uri = "gs://cloud-samples-data/vertex-ai/google-cloud-aiplatform-ci-artifacts/models/iris_xgboost/"
}

resource "google_vertex_ai_endpoint" "minimal" {
  display_name = "sample-endpoint"
  location     = "us-central1"
}
```

## Argument Reference

The following arguments are supported:


* `model` -
  (Required)
  The name of the model to deploy

* `dedicated_resources` -
  (Required)
  A description of resources that are dedicated to the DeployedModel, and that need a higher degree of manual configuration.
  Structure is [documented below](#nested_dedicated_resources).

* `endpoint` -
  (Required)
  The name of the endpoint to deploy to


<a name="nested_dedicated_resources"></a>The `dedicated_resources` block supports:

* `machine_spec` -
  (Required)
  Required. Immutable. The specification of a single machine used by the prediction.
  Structure is [documented below](#nested_machine_spec).

* `min_replica_count` -
  (Required)
  Required. Immutable. The minimum number of machine replicas this DeployedModel will be always deployed on. This value must be greater than or equal to 1. If traffic against the DeployedModel increases, it may dynamically be deployed onto more replicas, and as traffic decreases, some of these extra replicas may be freed.

* `max_replica_count` -
  (Optional)
  Immutable. The maximum number of replicas this DeployedModel may be deployed on when the traffic against it increases. If the requested value is too large, the deployment will error, but if deployment succeeds then the ability to scale the model to that many replicas is guaranteed (barring service outages). If traffic against the DeployedModel increases beyond what its replicas at maximum may handle, a portion of the traffic will be dropped. If this value is not provided, will use min_replica_count as the default value. The value of this field impacts the charge against Vertex CPU and GPU quotas. Specifically, you will be charged for max_replica_count * number of cores in the selected machine type) and (max_replica_count * number of GPUs per replica in the selected machine type).


<a name="nested_machine_spec"></a>The `machine_spec` block supports:

* `machine_type` -
  (Required)
  Immutable. The type of the machine. See the [list of machine types supported for prediction](https://cloud.google.com/vertex-ai/docs/predictions/configure-compute#machine-types) See the [list of machine types supported for custom training](https://cloud.google.com/vertex-ai/docs/training/configure-compute#machine-types). For DeployedModel this field is optional, and the default value is `n1-standard-2`. For BatchPredictionJob or as part of WorkerPoolSpec this field is required. TODO(rsurowka): Try to better unify the required vs optional.

- - -


* `location` -
  (Optional)
  The location of the endpoint

* `project` - (Optional) The ID of the project in which the resource belongs.
    If it is not provided, the provider project is used.


## Attributes Reference

In addition to the arguments listed above, the following computed attributes are exported:

* `id` - an identifier for the resource with format `{{project}}/{{location}}/{{endpoint}}/{{model}}`

* `deployed_model_id` -
  The deployed ID of the model in the endpoint


## Timeouts

This resource provides the following
[Timeouts](/docs/configuration/resources.html#timeouts) configuration options:

- `create` - Default is 20 minutes.
- `delete` - Default is 20 minutes.

## Import


ModelDeployment can be imported using any of these accepted formats:

```
$ terraform import google_vertex_ai_model_deployment.default {{project}}/{{location}}/{{endpoint}}/{{model}}
```

## User Project Overrides

This resource supports [User Project Overrides](https://www.terraform.io/docs/providers/google/guides/provider_reference.html#user_project_override).
