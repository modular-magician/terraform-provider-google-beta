---
# ----------------------------------------------------------------------------
#
#     ***     AUTO GENERATED CODE    ***    Type: MMv1     ***
#
# ----------------------------------------------------------------------------
#
#     This file is automatically generated by Magic Modules and manual
#     changes will be clobbered when the file is regenerated.
#
#     Please read more about how to change this file in
#     .github/CONTRIBUTING.md.
#
# ----------------------------------------------------------------------------
subcategory: "Vertex AI"
layout: "google"
page_title: "Google: google_vertex_ai_endpoint"
sidebar_current: "docs-google-vertex-ai-endpoint"
description: |-
  Models are deployed into it, and afterwards Endpoint is called to obtain predictions and explanations.
---

# google\_vertex\_ai\_endpoint

Models are deployed into it, and afterwards Endpoint is called to obtain predictions and explanations.


To get more information about Endpoint, see:

* [API documentation](https://cloud.google.com/vertex-ai/docs/reference/rest/v1/projects.locations.endpoints)
* How-to Guides
    * [Official Documentation](https://cloud.google.com/vertex-ai/docs)

<div class = "oics-button" style="float: right; margin: 0 0 -15px">
  <a href="https://console.cloud.google.com/cloudshell/open?cloudshell_git_repo=https%3A%2F%2Fgithub.com%2Fterraform-google-modules%2Fdocs-examples.git&cloudshell_working_dir=vertex_ai_endpoint&cloudshell_image=gcr.io%2Fgraphite-cloud-shell-images%2Fterraform%3Alatest&open_in_editor=main.tf&cloudshell_print=.%2Fmotd&cloudshell_tutorial=.%2Ftutorial.md" target="_blank">
    <img alt="Open in Cloud Shell" src="//gstatic.com/cloudssh/images/open-btn.svg" style="max-height: 44px; margin: 32px auto; max-width: 100%;">
  </a>
</div>
## Example Usage - Vertex Ai Endpoint


```hcl
resource "google_vertex_ai_endpoint" "endpoint" {
  provider = google-beta
  name     = "example-vertex-endpoint"
  labels = {
    foo = "bar"
  }
  region   = "us-central1"
}
```

## Argument Reference

The following arguments are supported:


* `display_name` -
  (Required)
  The user-defined name of the Endpoint. The name can be up to 128 characters long and can be consist of any UTF-8 characters.


- - -


* `description` -
  (Optional)
  The description of the Endpoint.

* `deployed_models` -
  (Optional)
  The list of models deployed in this Endpoint
  Structure is [documented below](#nested_deployed_models).

* `traffic_split` -
  (Optional)
  A map from a DeployedModel's ID to the percentage of this Endpoint's traffic that should be forwarded to that DeployedModel.  
  If a DeployedModel's ID is not listed in this map, then it receives no traffic.      
  The traffic percentage values must add up to 100, or map must be empty if the Endpoint is to not accept any traffic at a moment.

* `labels` -
  (Optional)
  A set of key/value label pairs to assign to this Endpoint.

* `encryption_spec` -
  (Optional)
  Customer-managed encryption key spec for the Endpoint. If set, this Endpoint and any sub-resources of this Endpoint will be secured by this key.
  Structure is [documented below](#nested_encryption_spec).

* `network` -
  (Optional)
  The full name of the Google Compute Engine network to which the Endpoint should be peered.  
  Private services access must already be configured for the network. If left unspecified, the Endpoint is not peered with any network.  
  Format: projects/{project}/global/networks/{network}. Where {project} is a project number, as in '12345', and {network} is network name.

* `model_deployment_monitoring_job` -
  (Optional)
  Resource name of the Model Monitoring job associated with this Endpoint if monitoring is enabled.

* `region` -
  (Optional)
  The region of the endpoint. eg us-central1

* `project` - (Optional) The ID of the project in which the resource belongs.
    If it is not provided, the provider project is used.


<a name="nested_deployed_models"></a>The `deployed_models` block supports:

* `id` -
  The resource name of the deployed model.

* `model` -
  (Required)
  The name of the Model that this is the deployment of.  
  Note that the Model may be in a different location than the DeployedModel's Endpoint.

* `create_time` -
  The timestamp of when the endpoint was created in RFC3339 UTC "Zulu" format, with nanosecond resolution and up to nine fractional digits.

* `service_account` -
  (Optional)
  The service account that the DeployedModel's container runs as. Specify the email address of the service account. If this service account is not specified, the container runs as a service account that doesn't have access to the resource project.  
  <br>
  Users deploying the Model must have the iam.serviceAccounts.actAs permission on this service account.

* `enable_container_logging` -
  (Optional)
  If true, the container of the DeployedModel instances will send stderr and stdout streams to Stackdriver Logging.  
  Only supported for custom-trained Models and AutoML Tabular Models.

* `enable_access_logging` -
  (Optional)
  These logs are like standard server access logs, containing information like timestamp and latency for each prediction request.  
  Note that Stackdriver logs may incur a cost, especially if your project receives prediction requests at a high queries per second rate (QPS). Estimate your costs before enabling this option.

* `private_endpoints` -
  Provide paths for users to send predict/explain/health requests directly to the deployed model services running on Cloud via private services access. This field is populated if network is configured.
  Structure is [documented below](#nested_private_endpoints).

* `dedicated_resources` -
  (Optional)
  A description of resources that are dedicated to the DeployedModel, and that need a higher degree of manual configuration.  
  Cannot be used with `automaticResources`
  Structure is [documented below](#nested_dedicated_resources).

* `automatic_resources` -
  (Optional)
  A description of resources that to large degree are decided by Vertex AI, and require only a modest additional configuration.  
  Cannot be used with `dedicatedResources`
  Structure is [documented below](#nested_automatic_resources).


<a name="nested_private_endpoints"></a>The `private_endpoints` block contains:

* `predict_http_uri` -
  Http(s) path to send prediction requests.

* `explain_http_uri` -
  Http(s) path to send explain requests.

* `health_http_uri` -
  Http(s) path to send health requests.

<a name="nested_dedicated_resources"></a>The `dedicated_resources` block supports:

* `machine_spec` -
  (Required)
  Immutable. The specification of a single machine used by the prediction.
  Structure is [documented below](#nested_machine_spec).

* `min_replica_count` -
  (Required)
  Immutable. The minimum number of machine replicas this DeployedModel will be always deployed on. This value must be greater than or equal to 1. If traffic against the DeployedModel increases, it may dynamically be deployed onto more replicas, and as traffic decreases, some of these extra replicas may be freed.

* `max_replica_count` -
  (Optional)
  Immutable. The maximum number of replicas this DeployedModel may be deployed on when the traffic against it increases. If the requested value is too large, the deployment will error, but if deployment succeeds then the ability to scale the model to that many replicas is guaranteed (barring service outages). If traffic against the DeployedModel increases beyond what its replicas at maximum may handle, a portion of the traffic will be dropped. If this value is not provided, will use `minReplicaCount` as the default value.


<a name="nested_machine_spec"></a>The `machine_spec` block supports:

* `machine_type` -
  (Optional)
  Immutable. The type of the machine.  
  See the [list of machine types supported for prediction](https://cloud.google.com/vertex-ai/docs/predictions/configure-compute#machine-types)  
  See the [list of machine types supported for custom training](https://cloud.google.com/vertex-ai/docs/training/configure-compute#machine-types).  
  For `DeployedModel` this field is optional, and the default value is `n1-standard-2`. For `BatchPredictionJob` or as part of `WorkerPoolSpec` this field is required.

* `accelerator_type` -
  (Optional)
  Immutable. The type of accelerator(s) that may be attached to the machine as per acceleratorCount.
  Possible values are `ACCELERATOR_TYPE_UNSPECIFIED`, `NVIDIA_TESLA_K80`, `NVIDIA_TESLA_P100`, `NVIDIA_TESLA_V100`, `NVIDIA_TESLA_P4`, `NVIDIA_TESLA_T4`, and `NVIDIA_TESLA_A100`.

* `accelerator_count` -
  (Optional)
  The number of accelerators to attach to the machine.

<a name="nested_automatic_resources"></a>The `automatic_resources` block supports:

* `min_replica_count` -
  (Optional)
  Immutable. The minimum number of replicas this DeployedModel will be always deployed on. If traffic against it increases, it may dynamically be deployed onto more replicas up to `maxReplicaCount``, and as traffic decreases, some of these extra replicas may be freed. If the requested value is too large, the deployment will error.

* `max_replica_count` -
  (Optional)
  Immutable. The maximum number of replicas this DeployedModel may be deployed on when the traffic against it increases. If the requested value is too large, the deployment will error, but if deployment succeeds then the ability to scale the model to that many replicas is guaranteed (barring service outages). If traffic against the DeployedModel increases beyond what its replicas at maximum may handle, a portion of the traffic will be dropped. If this value is not provided, a no upper bound for scaling under heavy traffic will be assume, though Vertex AI may be unable to scale beyond certain replica number.

<a name="nested_encryption_spec"></a>The `encryption_spec` block supports:

* `kms_key_name` -
  (Optional)
  Required. The Cloud KMS resource identifier of the customer managed encryption key used to protect a resource.  
  Has the form: projects/my-project/locations/my-region/keyRings/my-kr/cryptoKeys/my-key. The key needs to be in the same region as where the resource is created.

## Attributes Reference

In addition to the arguments listed above, the following computed attributes are exported:

* `id` - an identifier for the resource with format `projects/{{project}}/locations/{{region}}/endpoints/{{name}}`

* `name` -
  The resource name of the Endpoint.

* `etag` -
  Used to perform consistent read-modify-write updates.


## Timeouts

This resource provides the following
[Timeouts](/docs/configuration/resources.html#timeouts) configuration options:

- `create` - Default is 6 minutes.
- `update` - Default is 6 minutes.
- `delete` - Default is 10 minutes.

## Import


Endpoint can be imported using any of these accepted formats:

```
$ terraform import google_vertex_ai_endpoint.default projects/{{project}}/locations/{{region}}/endpoints/{{name}}
$ terraform import google_vertex_ai_endpoint.default {{project}}/{{region}}/{{name}}
$ terraform import google_vertex_ai_endpoint.default {{region}}/{{name}}
$ terraform import google_vertex_ai_endpoint.default {{name}}
```

## User Project Overrides

This resource supports [User Project Overrides](https://www.terraform.io/docs/providers/google/guides/provider_reference.html#user_project_override).
