// Copyright (c) HashiCorp, Inc.
// SPDX-License-Identifier: MPL-2.0

// ----------------------------------------------------------------------------
//
//     ***     AUTO GENERATED CODE    ***    Type: MMv1     ***
//
// ----------------------------------------------------------------------------
//
//     This file is automatically generated by Magic Modules and manual
//     changes will be clobbered when the file is regenerated.
//
//     Please read more about how to change this file in
//     .github/CONTRIBUTING.md.
//
// ----------------------------------------------------------------------------

package bigqueryanalyticshub

import (
	"fmt"
	"log"
	"reflect"
	"strings"
	"time"

	"github.com/hashicorp/terraform-plugin-sdk/v2/helper/customdiff"
	"github.com/hashicorp/terraform-plugin-sdk/v2/helper/schema"

	"github.com/hashicorp/terraform-provider-google-beta/google-beta/tpgresource"
	transport_tpg "github.com/hashicorp/terraform-provider-google-beta/google-beta/transport"

	"google.golang.org/api/googleapi"
)

func ResourceBigqueryAnalyticsHubListingSubscription() *schema.Resource {
	return &schema.Resource{
		Create: resourceBigqueryAnalyticsHubListingSubscriptionCreate,
		Read:   resourceBigqueryAnalyticsHubListingSubscriptionRead,
		Delete: resourceBigqueryAnalyticsHubListingSubscriptionDelete,

		Importer: &schema.ResourceImporter{
			State: resourceBigqueryAnalyticsHubListingSubscriptionImport,
		},

		Timeouts: &schema.ResourceTimeout{
			Create: schema.DefaultTimeout(20 * time.Minute),
			Delete: schema.DefaultTimeout(20 * time.Minute),
		},

		CustomizeDiff: customdiff.All(
			tpgresource.DefaultProviderProject,
		),

		Schema: map[string]*schema.Schema{
			"data_exchange_id": {
				Type:        schema.TypeString,
				Required:    true,
				ForceNew:    true,
				Description: `The ID of the data exchange. Must contain only Unicode letters, numbers (0-9), underscores (_). Should not use characters that require URL-escaping, or characters outside of ASCII, spaces.`,
			},
			"destination_dataset": {
				Type:        schema.TypeList,
				Required:    true,
				ForceNew:    true,
				Description: `The destination dataset for this subscription.`,
				MaxItems:    1,
				Elem: &schema.Resource{
					Schema: map[string]*schema.Schema{
						"dataset_reference": {
							Type:        schema.TypeList,
							Required:    true,
							ForceNew:    true,
							Description: `A reference that identifies the destination dataset.`,
							MaxItems:    1,
							Elem: &schema.Resource{
								Schema: map[string]*schema.Schema{
									"dataset_id": {
										Type:        schema.TypeString,
										Required:    true,
										ForceNew:    true,
										Description: `A unique ID for this dataset, without the project name. The ID must contain only letters (a-z, A-Z), numbers (0-9), or underscores (_). The maximum length is 1,024 characters.`,
									},
									"project_id": {
										Type:        schema.TypeString,
										Required:    true,
										ForceNew:    true,
										Description: `The ID of the project containing this dataset.`,
									},
								},
							},
						},
						"location": {
							Type:             schema.TypeString,
							Required:         true,
							ForceNew:         true,
							DiffSuppressFunc: tpgresource.CaseDiffSuppress,
							Description:      `The geographic location where the dataset should reside. See https://cloud.google.com/bigquery/docs/locations for supported locations.`,
						},
						"description": {
							Type:        schema.TypeString,
							Optional:    true,
							ForceNew:    true,
							Description: `A user-friendly description of the dataset.`,
						},
						"friendly_name": {
							Type:        schema.TypeString,
							Optional:    true,
							ForceNew:    true,
							Description: `A descriptive name for the dataset.`,
						},
						"labels": {
							Type:     schema.TypeMap,
							Optional: true,
							ForceNew: true,
							Description: `The labels associated with this dataset. You can use these to
organize and group your datasets.`,
							Elem: &schema.Schema{Type: schema.TypeString},
						},
					},
				},
			},
			"listing_id": {
				Type:        schema.TypeString,
				Required:    true,
				ForceNew:    true,
				Description: `The ID of the listing. Must contain only Unicode letters, numbers (0-9), underscores (_). Should not use characters that require URL-escaping, or characters outside of ASCII, spaces.`,
			},
			"location": {
				Type:        schema.TypeString,
				Required:    true,
				ForceNew:    true,
				Description: `The name of the location where the listing you want to subscribe to resides.`,
			},
			"name": {
				Type:        schema.TypeString,
				Computed:    true,
				Description: `The resource name of the subscription. e.g. "projects/myproject/locations/US/subscriptions/123"`,
			},
			"subscription_id": {
				Type:        schema.TypeString,
				Computed:    true,
				Description: `The subscription id used to reference the subscription.`,
			},

			"project": {
				Type:     schema.TypeString,
				Optional: true,
				Computed: true,
				ForceNew: true,
			},
		},
		UseJSONNumber: true,
	}
}

func resourceBigqueryAnalyticsHubListingSubscriptionCreate(d *schema.ResourceData, meta interface{}) error {
	config := meta.(*transport_tpg.Config)
	userAgent, err := tpgresource.GenerateUserAgentString(d, config.UserAgent)
	if err != nil {
		return err
	}

	obj := make(map[string]interface{})
	destinationDatasetProp, err := expandBigqueryAnalyticsHubListingSubscriptionDestinationDataset(d.Get("destination_dataset"), d, config)
	if err != nil {
		return err
	} else if v, ok := d.GetOkExists("destination_dataset"); !tpgresource.IsEmptyValue(reflect.ValueOf(destinationDatasetProp)) && (ok || !reflect.DeepEqual(v, destinationDatasetProp)) {
		obj["destinationDataset"] = destinationDatasetProp
	}

	url, err := tpgresource.ReplaceVars(d, config, "{{BigqueryAnalyticsHubBasePath}}projects/{{project}}/locations/{{location}}/dataExchanges/{{data_exchange_id}}/listings/{{listing_id}}:subscribe")
	if err != nil {
		return err
	}

	log.Printf("[DEBUG] Creating new ListingSubscription: %#v", obj)
	billingProject := ""

	project, err := tpgresource.GetProject(d, config)
	if err != nil {
		return fmt.Errorf("Error fetching project for ListingSubscription: %s", err)
	}
	billingProject = project

	// err == nil indicates that the billing_project value was found
	if bp, err := tpgresource.GetBillingProject(d, config); err == nil {
		billingProject = bp
	}

	res, err := transport_tpg.SendRequest(transport_tpg.SendRequestOptions{
		Config:    config,
		Method:    "POST",
		Project:   billingProject,
		RawURL:    url,
		UserAgent: userAgent,
		Body:      obj,
		Timeout:   d.Timeout(schema.TimeoutCreate),
	})
	if err != nil {
		return fmt.Errorf("Error creating ListingSubscription: %s", err)
	}

	// Store the ID now
	id, err := tpgresource.ReplaceVars(d, config, "{{name}}")
	if err != nil {
		return fmt.Errorf("Error constructing id: %s", err)
	}
	d.SetId(id)

	subscription, ok := res["subscription"]
	if ok {
		name, nok := subscription.(map[string]interface{})["name"]
		if nok {
			parts := strings.Split(name.(string), "/")
			d.SetId(name.(string))
			d.Set("name", name.(string))
			d.Set("subscription_id", parts[5])
		}
	}

	log.Printf("[DEBUG] Finished creating ListingSubscription %q: %#v", d.Id(), res)

	return resourceBigqueryAnalyticsHubListingSubscriptionRead(d, meta)
}

func resourceBigqueryAnalyticsHubListingSubscriptionRead(d *schema.ResourceData, meta interface{}) error {
	config := meta.(*transport_tpg.Config)
	userAgent, err := tpgresource.GenerateUserAgentString(d, config.UserAgent)
	if err != nil {
		return err
	}

	url, err := tpgresource.ReplaceVars(d, config, "{{BigqueryAnalyticsHubBasePath}}{{name}}")
	if err != nil {
		return err
	}

	billingProject := ""

	project, err := tpgresource.GetProject(d, config)
	if err != nil {
		return fmt.Errorf("Error fetching project for ListingSubscription: %s", err)
	}
	billingProject = project

	// err == nil indicates that the billing_project value was found
	if bp, err := tpgresource.GetBillingProject(d, config); err == nil {
		billingProject = bp
	}

	res, err := transport_tpg.SendRequest(transport_tpg.SendRequestOptions{
		Config:    config,
		Method:    "GET",
		Project:   billingProject,
		RawURL:    url,
		UserAgent: userAgent,
	})
	if err != nil {
		return transport_tpg.HandleNotFoundError(err, d, fmt.Sprintf("BigqueryAnalyticsHubListingSubscription %q", d.Id()))
	}

	res, err = resourceBigqueryAnalyticsHubListingSubscriptionDecoder(d, meta, res)
	if err != nil {
		return err
	}

	if res == nil {
		// Decoding the object has resulted in it being gone. It may be marked deleted
		log.Printf("[DEBUG] Removing BigqueryAnalyticsHubListingSubscription because it no longer exists.")
		d.SetId("")
		return nil
	}

	if err := d.Set("project", project); err != nil {
		return fmt.Errorf("Error reading ListingSubscription: %s", err)
	}

	// Terraform must set the top level schema field, but since this object contains collapsed properties
	// it's difficult to know what the top level should be. Instead we just loop over the map returned from flatten.
	if flattenedProp := flattenBigqueryAnalyticsHubListingSubscriptionSubscription(res["subscription"], d, config); flattenedProp != nil {
		if gerr, ok := flattenedProp.(*googleapi.Error); ok {
			return fmt.Errorf("Error reading ListingSubscription: %s", gerr)
		}
		casted := flattenedProp.([]interface{})[0]
		if casted != nil {
			for k, v := range casted.(map[string]interface{}) {
				if err := d.Set(k, v); err != nil {
					return fmt.Errorf("Error setting %s: %s", k, err)
				}
			}
		}
	}
	if err := d.Set("destination_dataset", flattenBigqueryAnalyticsHubListingSubscriptionDestinationDataset(res["destinationDataset"], d, config)); err != nil {
		return fmt.Errorf("Error reading ListingSubscription: %s", err)
	}

	return nil
}

func resourceBigqueryAnalyticsHubListingSubscriptionDelete(d *schema.ResourceData, meta interface{}) error {
	config := meta.(*transport_tpg.Config)
	userAgent, err := tpgresource.GenerateUserAgentString(d, config.UserAgent)
	if err != nil {
		return err
	}

	billingProject := ""

	project, err := tpgresource.GetProject(d, config)
	if err != nil {
		return fmt.Errorf("Error fetching project for ListingSubscription: %s", err)
	}
	billingProject = project

	url, err := tpgresource.ReplaceVars(d, config, "{{BigqueryAnalyticsHubBasePath}}{{name}}")
	if err != nil {
		return err
	}

	var obj map[string]interface{}
	log.Printf("[DEBUG] Deleting ListingSubscription %q", d.Id())

	// err == nil indicates that the billing_project value was found
	if bp, err := tpgresource.GetBillingProject(d, config); err == nil {
		billingProject = bp
	}

	res, err := transport_tpg.SendRequest(transport_tpg.SendRequestOptions{
		Config:    config,
		Method:    "DELETE",
		Project:   billingProject,
		RawURL:    url,
		UserAgent: userAgent,
		Body:      obj,
		Timeout:   d.Timeout(schema.TimeoutDelete),
	})
	if err != nil {
		return transport_tpg.HandleNotFoundError(err, d, "ListingSubscription")
	}

	log.Printf("[DEBUG] Finished deleting ListingSubscription %q: %#v", d.Id(), res)
	return nil
}

func resourceBigqueryAnalyticsHubListingSubscriptionImport(d *schema.ResourceData, meta interface{}) ([]*schema.ResourceData, error) {
	config := meta.(*transport_tpg.Config)
	if err := tpgresource.ParseImportId([]string{
		"^projects/(?P<project>[^/]+)/locations/(?P<location>[^/]+)/subscriptions/(?P<subscription_id>[^/]+)$",
		"^(?P<project>[^/]+)/(?P<location>[^/]+)/(?P<subscription_id>[^/]+)$",
		"^(?P<location>[^/]+)/(?P<subscription_id>[^/]+)$",
	}, d, config); err != nil {
		return nil, err
	}

	// Replace import id for the resource id
	id, err := tpgresource.ReplaceVars(d, config, "{{name}}")
	if err != nil {
		return nil, fmt.Errorf("Error constructing id: %s", err)
	}
	d.SetId(id)

	userAgent, err := tpgresource.GenerateUserAgentString(d, config.UserAgent)
	if err != nil {
		return nil, err
	}

	projectNumber := d.Get("project").(string)
	resourceManager := config.NewResourceManagerV3Client(userAgent)
	projectData, err := resourceManager.Projects.Get("projects/" + d.Get("project").(string)).Do()
	if err != nil {
		return nil, err
	}

	d.Set("project", projectData.ProjectId)

	id = fmt.Sprintf("projects/%s/locations/%s/subscriptions/%s",
		projectNumber,
		d.Get("location"),
		d.Get("subscription_id"))

	d.SetId(id)
	d.Set("name", id)

	return []*schema.ResourceData{d}, nil
}

func flattenBigqueryAnalyticsHubListingSubscriptionSubscription(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	if v == nil {
		return nil
	}
	original := v.(map[string]interface{})
	if len(original) == 0 {
		return nil
	}
	transformed := make(map[string]interface{})
	transformed["name"] =
		flattenBigqueryAnalyticsHubListingSubscriptionSubscriptionName(original["name"], d, config)
	transformed["subscription_id"] =
		flattenBigqueryAnalyticsHubListingSubscriptionSubscriptionSubscriptionId(original["subscription_id"], d, config)
	return []interface{}{transformed}
}
func flattenBigqueryAnalyticsHubListingSubscriptionSubscriptionName(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenBigqueryAnalyticsHubListingSubscriptionSubscriptionSubscriptionId(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenBigqueryAnalyticsHubListingSubscriptionDestinationDataset(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	if v == nil {
		return nil
	}
	original := v.(map[string]interface{})
	if len(original) == 0 {
		return nil
	}
	transformed := make(map[string]interface{})
	transformed["friendly_name"] =
		flattenBigqueryAnalyticsHubListingSubscriptionDestinationDatasetFriendlyName(original["friendlyName"], d, config)
	transformed["description"] =
		flattenBigqueryAnalyticsHubListingSubscriptionDestinationDatasetDescription(original["description"], d, config)
	transformed["labels"] =
		flattenBigqueryAnalyticsHubListingSubscriptionDestinationDatasetLabels(original["labels"], d, config)
	transformed["location"] =
		flattenBigqueryAnalyticsHubListingSubscriptionDestinationDatasetLocation(original["location"], d, config)
	transformed["dataset_reference"] =
		flattenBigqueryAnalyticsHubListingSubscriptionDestinationDatasetDatasetReference(original["datasetReference"], d, config)
	return []interface{}{transformed}
}
func flattenBigqueryAnalyticsHubListingSubscriptionDestinationDatasetFriendlyName(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenBigqueryAnalyticsHubListingSubscriptionDestinationDatasetDescription(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenBigqueryAnalyticsHubListingSubscriptionDestinationDatasetLabels(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

// Older Datasets in BigQuery have no Location set in the API response. This may be an issue when importing
// datasets created before BigQuery was available in multiple zones. We can safely assume that these datasets
// are in the US, as this was the default at the time.
func flattenBigqueryAnalyticsHubListingSubscriptionDestinationDatasetLocation(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	if v == nil {
		return "US"
	}
	return v
}

func flattenBigqueryAnalyticsHubListingSubscriptionDestinationDatasetDatasetReference(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	if v == nil {
		return nil
	}
	original := v.(map[string]interface{})
	if len(original) == 0 {
		return nil
	}
	transformed := make(map[string]interface{})
	transformed["dataset_id"] =
		flattenBigqueryAnalyticsHubListingSubscriptionDestinationDatasetDatasetReferenceDatasetId(original["datasetId"], d, config)
	transformed["project_id"] =
		flattenBigqueryAnalyticsHubListingSubscriptionDestinationDatasetDatasetReferenceProjectId(original["projectId"], d, config)
	return []interface{}{transformed}
}
func flattenBigqueryAnalyticsHubListingSubscriptionDestinationDatasetDatasetReferenceDatasetId(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenBigqueryAnalyticsHubListingSubscriptionDestinationDatasetDatasetReferenceProjectId(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func expandBigqueryAnalyticsHubListingSubscriptionDestinationDataset(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (interface{}, error) {
	l := v.([]interface{})
	if len(l) == 0 || l[0] == nil {
		return nil, nil
	}
	raw := l[0]
	original := raw.(map[string]interface{})
	transformed := make(map[string]interface{})

	transformedFriendlyName, err := expandBigqueryAnalyticsHubListingSubscriptionDestinationDatasetFriendlyName(original["friendly_name"], d, config)
	if err != nil {
		return nil, err
	} else if val := reflect.ValueOf(transformedFriendlyName); val.IsValid() && !tpgresource.IsEmptyValue(val) {
		transformed["friendlyName"] = transformedFriendlyName
	}

	transformedDescription, err := expandBigqueryAnalyticsHubListingSubscriptionDestinationDatasetDescription(original["description"], d, config)
	if err != nil {
		return nil, err
	} else if val := reflect.ValueOf(transformedDescription); val.IsValid() && !tpgresource.IsEmptyValue(val) {
		transformed["description"] = transformedDescription
	}

	transformedLabels, err := expandBigqueryAnalyticsHubListingSubscriptionDestinationDatasetLabels(original["labels"], d, config)
	if err != nil {
		return nil, err
	} else if val := reflect.ValueOf(transformedLabels); val.IsValid() && !tpgresource.IsEmptyValue(val) {
		transformed["labels"] = transformedLabels
	}

	transformedLocation, err := expandBigqueryAnalyticsHubListingSubscriptionDestinationDatasetLocation(original["location"], d, config)
	if err != nil {
		return nil, err
	} else if val := reflect.ValueOf(transformedLocation); val.IsValid() && !tpgresource.IsEmptyValue(val) {
		transformed["location"] = transformedLocation
	}

	transformedDatasetReference, err := expandBigqueryAnalyticsHubListingSubscriptionDestinationDatasetDatasetReference(original["dataset_reference"], d, config)
	if err != nil {
		return nil, err
	} else if val := reflect.ValueOf(transformedDatasetReference); val.IsValid() && !tpgresource.IsEmptyValue(val) {
		transformed["datasetReference"] = transformedDatasetReference
	}

	return transformed, nil
}

func expandBigqueryAnalyticsHubListingSubscriptionDestinationDatasetFriendlyName(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (interface{}, error) {
	return v, nil
}

func expandBigqueryAnalyticsHubListingSubscriptionDestinationDatasetDescription(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (interface{}, error) {
	return v, nil
}

func expandBigqueryAnalyticsHubListingSubscriptionDestinationDatasetLabels(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (map[string]string, error) {
	if v == nil {
		return map[string]string{}, nil
	}
	m := make(map[string]string)
	for k, val := range v.(map[string]interface{}) {
		m[k] = val.(string)
	}
	return m, nil
}

func expandBigqueryAnalyticsHubListingSubscriptionDestinationDatasetLocation(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (interface{}, error) {
	return v, nil
}

func expandBigqueryAnalyticsHubListingSubscriptionDestinationDatasetDatasetReference(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (interface{}, error) {
	l := v.([]interface{})
	if len(l) == 0 || l[0] == nil {
		return nil, nil
	}
	raw := l[0]
	original := raw.(map[string]interface{})
	transformed := make(map[string]interface{})

	transformedDatasetId, err := expandBigqueryAnalyticsHubListingSubscriptionDestinationDatasetDatasetReferenceDatasetId(original["dataset_id"], d, config)
	if err != nil {
		return nil, err
	} else if val := reflect.ValueOf(transformedDatasetId); val.IsValid() && !tpgresource.IsEmptyValue(val) {
		transformed["datasetId"] = transformedDatasetId
	}

	transformedProjectId, err := expandBigqueryAnalyticsHubListingSubscriptionDestinationDatasetDatasetReferenceProjectId(original["project_id"], d, config)
	if err != nil {
		return nil, err
	} else if val := reflect.ValueOf(transformedProjectId); val.IsValid() && !tpgresource.IsEmptyValue(val) {
		transformed["projectId"] = transformedProjectId
	}

	return transformed, nil
}

func expandBigqueryAnalyticsHubListingSubscriptionDestinationDatasetDatasetReferenceDatasetId(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (interface{}, error) {
	return v, nil
}

func expandBigqueryAnalyticsHubListingSubscriptionDestinationDatasetDatasetReferenceProjectId(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (interface{}, error) {
	return v, nil
}

func resourceBigqueryAnalyticsHubListingSubscriptionDecoder(d *schema.ResourceData, meta interface{}, res map[string]interface{}) (map[string]interface{}, error) {
	// The subscription API has several unconventional attributes to it and
	// requires a bit of work to get into the correct format.
	config := meta.(*transport_tpg.Config)
	userAgent, err := tpgresource.GenerateUserAgentString(d, config.UserAgent)
	if err != nil {
		return res, err
	}

	// Create a BigQuery client to look up the destination dataset metadata.
	client := config.NewBigQueryClient(userAgent)
	// Create a ResourceManager client to look-up project information.
	resourceManager := config.NewResourceManagerV3Client(userAgent)

	// Loop through the linked dataset list and extract the target dataset URI.
	// Note that in the case of linked datasets to an listing, there is only
	// one item in the map at any given time.
	var targetDataset string
	linkedDatasetMap := res["linkedDatasetMap"].(map[string]interface{})
	for _, linkedDataset := range linkedDatasetMap {
		targetDataset = linkedDataset.(map[string]interface{})["linkedDataset"].(string)
	}

	// Get the parts of the target dataset.
	parts := strings.Split(targetDataset, "/")

	// Look up the project data for the target dataset, since the subscription API
	// does not return the project ID.
	projectData, err := resourceManager.Projects.Get("projects/" + parts[1]).Do()
	if err != nil {
		return nil, err
	}

	// Get the target dataset metadata, as the subscription API does not return the
	// properties of the linked dataset for matching against Terraform state.
	md, err := client.Datasets.Get(parts[1], parts[3]).Do()
	if err != nil {
		return nil, err
	}

	// Copy the labels for the target dataset into the correct type of map
	// expected by the Terraform API.
	labels := make(map[string]interface{})
	for k, v := range md.Labels {
		labels[k] = v
	}

	// Fill in the results and return them.
	res["destinationDataset"] = map[string]interface{}{
		"description":  md.Description,
		"friendlyName": md.FriendlyName,
		"location":     md.Location,
		"datasetReference": map[string]interface{}{
			"projectId": projectData.ProjectId,
			"datasetId": strings.Split(md.Id, ":")[1],
		},
		"labels": labels,
	}

	return res, nil
}
