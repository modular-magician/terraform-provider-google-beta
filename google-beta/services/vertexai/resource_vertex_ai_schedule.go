// Copyright (c) HashiCorp, Inc.
// SPDX-License-Identifier: MPL-2.0

// ----------------------------------------------------------------------------
//
//     ***     AUTO GENERATED CODE    ***    Type: MMv1     ***
//
// ----------------------------------------------------------------------------
//
//     This file is automatically generated by Magic Modules and manual
//     changes will be clobbered when the file is regenerated.
//
//     Please read more about how to change this file in
//     .github/CONTRIBUTING.md.
//
// ----------------------------------------------------------------------------

package vertexai

import (
	"encoding/json"
	"fmt"
	"log"
	"reflect"
	"time"

	"github.com/hashicorp/terraform-plugin-sdk/v2/helper/schema"
	"github.com/hashicorp/terraform-plugin-sdk/v2/helper/structure"
	"github.com/hashicorp/terraform-plugin-sdk/v2/helper/validation"

	"github.com/hashicorp/terraform-provider-google-beta/google-beta/tpgresource"
	transport_tpg "github.com/hashicorp/terraform-provider-google-beta/google-beta/transport"
	"github.com/hashicorp/terraform-provider-google-beta/google-beta/verify"
)

func ResourceVertexAISchedule() *schema.Resource {
	return &schema.Resource{
		Create: resourceVertexAIScheduleCreate,
		Read:   resourceVertexAIScheduleRead,
		Update: resourceVertexAIScheduleUpdate,
		Delete: resourceVertexAIScheduleDelete,

		Importer: &schema.ResourceImporter{
			State: resourceVertexAIScheduleImport,
		},

		Timeouts: &schema.ResourceTimeout{
			Create: schema.DefaultTimeout(20 * time.Minute),
			Update: schema.DefaultTimeout(20 * time.Minute),
			Delete: schema.DefaultTimeout(20 * time.Minute),
		},

		Schema: map[string]*schema.Schema{
			"display_name": {
				Type:        schema.TypeString,
				Required:    true,
				Description: `User provided name of the Schedule. The name can be up to 128 characters long and can consist of any UTF-8 characters.`,
			},
			"max_concurrent_run_count": {
				Type:     schema.TypeInt,
				Required: true,
				Description: `Maximum number of runs that can be started concurrently for this
Schedule. This is the limit for starting the scheduled requests and not the
execution of the operations/jobs created by the requests (if applicable).`,
			},
			"name": {
				Type:        schema.TypeString,
				Required:    true,
				ForceNew:    true,
				Description: `The resource name of the Schedule.`,
			},
			"region": {
				Type:        schema.TypeString,
				Required:    true,
				ForceNew:    true,
				Description: `Region where the scheduler job resides`,
			},
			"allow_queueing": {
				Type:     schema.TypeBool,
				Optional: true,
				Description: `Whether new scheduled runs can be queued when max_concurrent_runs
limit is reached. If set to true, new runs will be queued instead of skipped.
Default to false.`,
			},
			"catch_up": {
				Type:     schema.TypeBool,
				Computed: true,
				Optional: true,
				Description: `Whether to backfill missed runs when the schedule is resumed from PAUSED state.
If set to true, all missed runs will be scheduled. New runs will be scheduled after the
backfill is complete. Default to false.`,
			},
			"create_pipeline_job_request": {
				Type:     schema.TypeList,
				Optional: true,
				Description: `Request for PipelineService.CreatePipelineJob.
CreatePipelineJobRequest.parent field is required
(format: projects/{project}/locations/{location}).`,
				MaxItems: 1,
				Elem: &schema.Resource{
					Schema: map[string]*schema.Schema{
						"parent": {
							Type:        schema.TypeString,
							Required:    true,
							Description: `The resource name of the Location to create the PipelineJob in. Format: projects/{project}/locations/{location}`,
						},
						"pipeline_job": {
							Type:        schema.TypeList,
							Required:    true,
							Description: `The PipelineJob to create.`,
							MaxItems:    1,
							Elem: &schema.Resource{
								Schema: map[string]*schema.Schema{
									"runtime_config": {
										Type:        schema.TypeList,
										Required:    true,
										Description: `Runtime config of the pipeline.`,
										MaxItems:    1,
										Elem: &schema.Resource{
											Schema: map[string]*schema.Schema{
												"gcs_output_directory": {
													Type:     schema.TypeString,
													Required: true,
													Description: `A path in a Cloud Storage bucket, which will be treated as the root
output directory of the pipeline. It is used by the system to generate the paths
of output artifacts. The artifact paths are generated with a sub-path pattern
{job_id}/{taskId}/{output_key} under the specified output directory.
The service account specified in this pipeline must have the storage.objects.get
and storage.objects.create permissions for this bucket.`,
												},
												"failure_policy": {
													Type:         schema.TypeString,
													Optional:     true,
													ValidateFunc: verify.ValidateEnum([]string{"PIPELINE_FAILURE_POLICY_UNSPECIFIED", "PIPELINE_FAILURE_POLICY_FAIL_SLOW", "PIPELINE_FAILURE_POLICY_FAIL_FAST", ""}),
													Description: `Represents the failure policy of a pipeline. Currently, the default of a pipeline
is that the pipeline will continue to run until no more tasks can be executed,
also known as PIPELINE_FAILURE_POLICY_FAIL_SLOW. However, if a pipeline is set
to PIPELINE_FAILURE_POLICY_FAIL_FAST, it will stop scheduling any new tasks when
a task has failed. Any scheduled tasks will continue to completion. Default value: "PIPELINE_FAILURE_POLICY_UNSPECIFIED" Possible values: ["PIPELINE_FAILURE_POLICY_UNSPECIFIED", "PIPELINE_FAILURE_POLICY_FAIL_SLOW", "PIPELINE_FAILURE_POLICY_FAIL_FAST"]`,
													Default: "PIPELINE_FAILURE_POLICY_UNSPECIFIED",
												},
												"input_artifacts": {
													Type:     schema.TypeMap,
													Optional: true,
													Description: `The runtime artifacts of the PipelineJob. The key will be the input artifact name and the value
would be an Artifact resource id from MLMD, which is the last portion of an artifact resource name:
projects/{project}/locations/{location}/metadataStores/default/artifacts/{artifactId}.
The artifact must stay within the same project, location and default metadatastore as the pipeline.`,
													Elem: &schema.Schema{Type: schema.TypeString},
												},
												"parameter_values": {
													Type:         schema.TypeString,
													Optional:     true,
													ValidateFunc: validation.StringIsJSON,
													StateFunc:    func(v interface{}) string { s, _ := structure.NormalizeJsonString(v); return s },
													Description: `The runtime parameters of the PipelineJob. The parameters will be passed into
PipelineJob.pipeline_spec to replace the placeholders at runtime. This field
is used by pipelines built using PipelineJob.pipeline_spec.schema_version 2.1.0,
such as pipelines built using Kubeflow Pipelines SDK 1.9 or higher and the v2 DSL.
Expects a JSON-encoded string.`,
												},
												"parameters": {
													Type:         schema.TypeString,
													Optional:     true,
													ValidateFunc: validation.StringIsJSON,
													StateFunc:    func(v interface{}) string { s, _ := structure.NormalizeJsonString(v); return s },
													Description: `Deprecated. Use RuntimeConfig.parameter_values instead. The runtime parameters of the PipelineJob.
The parameters will be passed into PipelineJob.pipeline_spec to replace the placeholders at runtime.
This field is used by pipelines built using PipelineJob.pipeline_spec.schema_version 2.0.0 or lower,
such as pipelines built using Kubeflow Pipelines SDK 1.8 or lower. Expects a JSON-encoded string.`,
												},
											},
										},
									},
									"display_name": {
										Type:     schema.TypeString,
										Optional: true,
										Description: `The display name of the Pipeline. The name can be up to 128 characters long
and can consist of any UTF-8 characters.`,
									},
									"labels": {
										Type:     schema.TypeMap,
										Optional: true,
										Description: `The labels with user-defined metadata to organize PipelineJob.
Label keys and values can be no longer than 64 characters
(Unicode codepoints), can only contain lowercase letters,
numeric characters, underscores and dashes. International
characters are allowed. See https://goo.gl/xmQnxf for more
information and examples of labels.`,
										Elem: &schema.Schema{Type: schema.TypeString},
									},
									"network": {
										Type:     schema.TypeString,
										Optional: true,
										Description: `The full name of the Compute Engine network to which the Pipeline Job's workload
should be peered. For example, projects/12345/global/networks/myVPC. Format is
of the form projects/{project}/global/networks/{network}. Where {project} is a
project number, as in 12345, and {network} is a network name.
Private services access must already be configured for the network.
Pipeline job will apply the network configuration to the Google Cloud resources
being launched, if applied, such as Vertex AI Training or Dataflow job.
If left unspecified, the workload is not peered with any network.`,
									},
									"pipeline_spec": {
										Type:         schema.TypeString,
										Optional:     true,
										ValidateFunc: validation.StringIsJSON,
										StateFunc:    func(v interface{}) string { s, _ := structure.NormalizeJsonString(v); return s },
										Description:  `The spec of the pipeline. Expects a JSON-encoded string.`,
									},
									"service_account": {
										Type:     schema.TypeString,
										Optional: true,
										Description: `The service account that the pipeline workload runs as.
If not specified, the Compute Engine default service account
in the project will be used.
See https://cloud.google.com/compute/docs/access/service-accounts#default_service_account
Users starting the pipeline must have the iam.serviceAccounts.actAs
permission on this service account.`,
									},
									"template_uri": {
										Type:        schema.TypeString,
										Optional:    true,
										Description: `A template uri from where the PipelineJob.pipeline_spec, if empty, will be downloaded.`,
									},
								},
							},
						},
					},
				},
			},
			"cron": {
				Type:     schema.TypeString,
				Optional: true,
				Description: `The scheduled run time based on the user-specified schedule.
A timestamp in RFC3339 UTC "Zulu" format, with nanosecond
resolution and up to nine fractional digits. Examples:
"2014-10-02T15:01:23Z" and "2014-10-02T15:01:23.045123456Z".`,
			},
			"end_time": {
				Type:     schema.TypeString,
				Optional: true,
				Description: `Timestamp after which no new runs can be scheduled. If specified,
The schedule will be completed when either endTime is reached or when
scheduled_run_count >= maxRunCount. If not specified, new runs will keep
getting scheduled until this Schedule is paused or deleted. Already scheduled
runs will be allowed to complete. Unset if not specified. A timestamp in
RFC3339 UTC "Zulu" format, with nanosecond resolution and up to nine
fractional digits. Examples: "2014-10-02T15:01:23Z" and
"2014-10-02T15:01:23.045123456Z".`,
			},
			"max_run_count": {
				Type:     schema.TypeString,
				Optional: true,
				Description: `Maximum run count of the schedule. If specified, The schedule will
be completed when either startedRunCount >= maxRunCount or when endTime is
reached. If not specified, new runs will keep getting scheduled until this
Schedule is paused or deleted. Already scheduled runs will be allowed to
complete. Unset if not specified.`,
			},
			"paused": {
				Type:        schema.TypeBool,
				Computed:    true,
				Optional:    true,
				Description: `Sets the job to a paused state. Jobs default to being enabled when this property is not set.`,
			},
			"start_time": {
				Type:     schema.TypeString,
				Optional: true,
				Description: `Timestamp after which the first run can be scheduled. Default to
Schedule create time if not specified. A timestamp in RFC3339 UTC "Zulu"
format, with nanosecond resolution and up to nine fractional digits.
Examples: "2014-10-02T15:01:23Z" and "2014-10-02T15:01:23.045123456Z".`,
			},
			"state": {
				Type:        schema.TypeString,
				Computed:    true,
				Description: `State of the job.`,
			},
			"project": {
				Type:     schema.TypeString,
				Optional: true,
				Computed: true,
				ForceNew: true,
			},
		},
		UseJSONNumber: true,
	}
}

func resourceVertexAIScheduleCreate(d *schema.ResourceData, meta interface{}) error {
	config := meta.(*transport_tpg.Config)
	userAgent, err := tpgresource.GenerateUserAgentString(d, config.UserAgent)
	if err != nil {
		return err
	}

	obj := make(map[string]interface{})
	nameProp, err := expandVertexAIScheduleName(d.Get("name"), d, config)
	if err != nil {
		return err
	} else if v, ok := d.GetOkExists("name"); !tpgresource.IsEmptyValue(reflect.ValueOf(nameProp)) && (ok || !reflect.DeepEqual(v, nameProp)) {
		obj["name"] = nameProp
	}
	displayNameProp, err := expandVertexAIScheduleDisplayName(d.Get("display_name"), d, config)
	if err != nil {
		return err
	} else if v, ok := d.GetOkExists("display_name"); !tpgresource.IsEmptyValue(reflect.ValueOf(displayNameProp)) && (ok || !reflect.DeepEqual(v, displayNameProp)) {
		obj["displayName"] = displayNameProp
	}
	cronProp, err := expandVertexAIScheduleCron(d.Get("cron"), d, config)
	if err != nil {
		return err
	} else if v, ok := d.GetOkExists("cron"); !tpgresource.IsEmptyValue(reflect.ValueOf(cronProp)) && (ok || !reflect.DeepEqual(v, cronProp)) {
		obj["cron"] = cronProp
	}
	startTimeProp, err := expandVertexAIScheduleStartTime(d.Get("start_time"), d, config)
	if err != nil {
		return err
	} else if v, ok := d.GetOkExists("start_time"); !tpgresource.IsEmptyValue(reflect.ValueOf(startTimeProp)) && (ok || !reflect.DeepEqual(v, startTimeProp)) {
		obj["startTime"] = startTimeProp
	}
	endTimeProp, err := expandVertexAIScheduleEndTime(d.Get("end_time"), d, config)
	if err != nil {
		return err
	} else if v, ok := d.GetOkExists("end_time"); !tpgresource.IsEmptyValue(reflect.ValueOf(endTimeProp)) && (ok || !reflect.DeepEqual(v, endTimeProp)) {
		obj["endTime"] = endTimeProp
	}
	maxRunCountProp, err := expandVertexAIScheduleMaxRunCount(d.Get("max_run_count"), d, config)
	if err != nil {
		return err
	} else if v, ok := d.GetOkExists("max_run_count"); !tpgresource.IsEmptyValue(reflect.ValueOf(maxRunCountProp)) && (ok || !reflect.DeepEqual(v, maxRunCountProp)) {
		obj["maxRunCount"] = maxRunCountProp
	}
	pausedProp, err := expandVertexAISchedulePaused(d.Get("paused"), d, config)
	if err != nil {
		return err
	} else if v, ok := d.GetOkExists("paused"); !tpgresource.IsEmptyValue(reflect.ValueOf(pausedProp)) && (ok || !reflect.DeepEqual(v, pausedProp)) {
		obj["paused"] = pausedProp
	}
	catchUpProp, err := expandVertexAIScheduleCatchUp(d.Get("catch_up"), d, config)
	if err != nil {
		return err
	} else if v, ok := d.GetOkExists("catch_up"); !tpgresource.IsEmptyValue(reflect.ValueOf(catchUpProp)) && (ok || !reflect.DeepEqual(v, catchUpProp)) {
		obj["catchUp"] = catchUpProp
	}
	maxConcurrentRunCountProp, err := expandVertexAIScheduleMaxConcurrentRunCount(d.Get("max_concurrent_run_count"), d, config)
	if err != nil {
		return err
	} else if v, ok := d.GetOkExists("max_concurrent_run_count"); !tpgresource.IsEmptyValue(reflect.ValueOf(maxConcurrentRunCountProp)) && (ok || !reflect.DeepEqual(v, maxConcurrentRunCountProp)) {
		obj["maxConcurrentRunCount"] = maxConcurrentRunCountProp
	}
	allowQueueingProp, err := expandVertexAIScheduleAllowQueueing(d.Get("allow_queueing"), d, config)
	if err != nil {
		return err
	} else if v, ok := d.GetOkExists("allow_queueing"); !tpgresource.IsEmptyValue(reflect.ValueOf(allowQueueingProp)) && (ok || !reflect.DeepEqual(v, allowQueueingProp)) {
		obj["allowQueueing"] = allowQueueingProp
	}
	createPipelineJobRequestProp, err := expandVertexAIScheduleCreatePipelineJobRequest(d.Get("create_pipeline_job_request"), d, config)
	if err != nil {
		return err
	} else if v, ok := d.GetOkExists("create_pipeline_job_request"); !tpgresource.IsEmptyValue(reflect.ValueOf(createPipelineJobRequestProp)) && (ok || !reflect.DeepEqual(v, createPipelineJobRequestProp)) {
		obj["createPipelineJobRequest"] = createPipelineJobRequestProp
	}

	obj, err = resourceVertexAIScheduleEncoder(d, meta, obj)
	if err != nil {
		return err
	}

	url, err := tpgresource.ReplaceVars(d, config, "{{VertexAIBasePath}}projects/{{project}}/locations/{{region}}/schedules")
	if err != nil {
		return err
	}

	log.Printf("[DEBUG] Creating new Schedule: %#v", obj)
	billingProject := ""

	project, err := tpgresource.GetProject(d, config)
	if err != nil {
		return fmt.Errorf("Error fetching project for Schedule: %s", err)
	}
	billingProject = project

	// err == nil indicates that the billing_project value was found
	if bp, err := tpgresource.GetBillingProject(d, config); err == nil {
		billingProject = bp
	}

	res, err := transport_tpg.SendRequest(transport_tpg.SendRequestOptions{
		Config:    config,
		Method:    "POST",
		Project:   billingProject,
		RawURL:    url,
		UserAgent: userAgent,
		Body:      obj,
		Timeout:   d.Timeout(schema.TimeoutCreate),
	})
	if err != nil {
		return fmt.Errorf("Error creating Schedule: %s", err)
	}

	// Store the ID now
	id, err := tpgresource.ReplaceVars(d, config, "projects/{{project}}/locations/{{region}}/schedules/{{name}}")
	if err != nil {
		return fmt.Errorf("Error constructing id: %s", err)
	}
	d.SetId(id)

	endpoint := "resume" // Default to enabled
	logSuccessMsg := "Schedule state has been set to ACTIVE"
	reqBody := make(map[string]interface{})
	if paused, pausedOk := d.GetOk("paused"); pausedOk && paused.(bool) {
		endpoint = "pause"
		logSuccessMsg = "Schedule state has been set to PAUSED"
	} else if catchUp, catchUpOk := d.GetOk("catchUp"); catchUpOk && catchUp.(bool) {
		reqBody["catchUp"] = catchUp
	}

	linkTmpl := fmt.Sprintf("{{VertexAIBasePath}projects/{{project}}/locations/{{region}}/schedules/{{name}}:%s", endpoint)
	url, err = tpgresource.ReplaceVars(d, config, linkTmpl)
	if err != nil {
		return err
	}

	_, err = transport_tpg.SendRequest(transport_tpg.SendRequestOptions{
		Config:    config,
		Method:    "POST",
		Project:   billingProject,
		RawURL:    url,
		UserAgent: userAgent,
		Body:      reqBody,
		Timeout:   d.Timeout(schema.TimeoutUpdate),
	})
	if err != nil {
		return fmt.Errorf("Error setting Vertex Schedule status: %s", err)
	}

	log.Printf("[DEBUG] Finished updating Schedule %q status: %s", d.Id(), logSuccessMsg)

	log.Printf("[DEBUG] Finished creating Schedule %q: %#v", d.Id(), res)

	return resourceVertexAIScheduleRead(d, meta)
}

func resourceVertexAIScheduleRead(d *schema.ResourceData, meta interface{}) error {
	config := meta.(*transport_tpg.Config)
	userAgent, err := tpgresource.GenerateUserAgentString(d, config.UserAgent)
	if err != nil {
		return err
	}

	url, err := tpgresource.ReplaceVars(d, config, "{{VertexAIBasePath}}projects/{{project}}/locations/{{region}}/schedules/{{name}}")
	if err != nil {
		return err
	}

	billingProject := ""

	project, err := tpgresource.GetProject(d, config)
	if err != nil {
		return fmt.Errorf("Error fetching project for Schedule: %s", err)
	}
	billingProject = project

	// err == nil indicates that the billing_project value was found
	if bp, err := tpgresource.GetBillingProject(d, config); err == nil {
		billingProject = bp
	}

	res, err := transport_tpg.SendRequest(transport_tpg.SendRequestOptions{
		Config:    config,
		Method:    "GET",
		Project:   billingProject,
		RawURL:    url,
		UserAgent: userAgent,
	})
	if err != nil {
		return transport_tpg.HandleNotFoundError(err, d, fmt.Sprintf("VertexAISchedule %q", d.Id()))
	}

	if err := d.Set("project", project); err != nil {
		return fmt.Errorf("Error reading Schedule: %s", err)
	}

	if err := d.Set("name", flattenVertexAIScheduleName(res["name"], d, config)); err != nil {
		return fmt.Errorf("Error reading Schedule: %s", err)
	}
	if err := d.Set("display_name", flattenVertexAIScheduleDisplayName(res["displayName"], d, config)); err != nil {
		return fmt.Errorf("Error reading Schedule: %s", err)
	}
	if err := d.Set("cron", flattenVertexAIScheduleCron(res["cron"], d, config)); err != nil {
		return fmt.Errorf("Error reading Schedule: %s", err)
	}
	if err := d.Set("start_time", flattenVertexAIScheduleStartTime(res["startTime"], d, config)); err != nil {
		return fmt.Errorf("Error reading Schedule: %s", err)
	}
	if err := d.Set("end_time", flattenVertexAIScheduleEndTime(res["endTime"], d, config)); err != nil {
		return fmt.Errorf("Error reading Schedule: %s", err)
	}
	if err := d.Set("max_run_count", flattenVertexAIScheduleMaxRunCount(res["maxRunCount"], d, config)); err != nil {
		return fmt.Errorf("Error reading Schedule: %s", err)
	}
	if err := d.Set("state", flattenVertexAIScheduleState(res["state"], d, config)); err != nil {
		return fmt.Errorf("Error reading Schedule: %s", err)
	}
	if err := d.Set("paused", flattenVertexAISchedulePaused(res["paused"], d, config)); err != nil {
		return fmt.Errorf("Error reading Schedule: %s", err)
	}
	if err := d.Set("catch_up", flattenVertexAIScheduleCatchUp(res["catchUp"], d, config)); err != nil {
		return fmt.Errorf("Error reading Schedule: %s", err)
	}
	if err := d.Set("max_concurrent_run_count", flattenVertexAIScheduleMaxConcurrentRunCount(res["maxConcurrentRunCount"], d, config)); err != nil {
		return fmt.Errorf("Error reading Schedule: %s", err)
	}
	if err := d.Set("allow_queueing", flattenVertexAIScheduleAllowQueueing(res["allowQueueing"], d, config)); err != nil {
		return fmt.Errorf("Error reading Schedule: %s", err)
	}
	if err := d.Set("create_pipeline_job_request", flattenVertexAIScheduleCreatePipelineJobRequest(res["createPipelineJobRequest"], d, config)); err != nil {
		return fmt.Errorf("Error reading Schedule: %s", err)
	}

	return nil
}

func resourceVertexAIScheduleUpdate(d *schema.ResourceData, meta interface{}) error {
	config := meta.(*transport_tpg.Config)
	userAgent, err := tpgresource.GenerateUserAgentString(d, config.UserAgent)
	if err != nil {
		return err
	}

	billingProject := ""

	project, err := tpgresource.GetProject(d, config)
	if err != nil {
		return fmt.Errorf("Error fetching project for Schedule: %s", err)
	}
	billingProject = project

	obj := make(map[string]interface{})
	displayNameProp, err := expandVertexAIScheduleDisplayName(d.Get("display_name"), d, config)
	if err != nil {
		return err
	} else if v, ok := d.GetOkExists("display_name"); !tpgresource.IsEmptyValue(reflect.ValueOf(v)) && (ok || !reflect.DeepEqual(v, displayNameProp)) {
		obj["displayName"] = displayNameProp
	}
	cronProp, err := expandVertexAIScheduleCron(d.Get("cron"), d, config)
	if err != nil {
		return err
	} else if v, ok := d.GetOkExists("cron"); !tpgresource.IsEmptyValue(reflect.ValueOf(v)) && (ok || !reflect.DeepEqual(v, cronProp)) {
		obj["cron"] = cronProp
	}
	startTimeProp, err := expandVertexAIScheduleStartTime(d.Get("start_time"), d, config)
	if err != nil {
		return err
	} else if v, ok := d.GetOkExists("start_time"); !tpgresource.IsEmptyValue(reflect.ValueOf(v)) && (ok || !reflect.DeepEqual(v, startTimeProp)) {
		obj["startTime"] = startTimeProp
	}
	endTimeProp, err := expandVertexAIScheduleEndTime(d.Get("end_time"), d, config)
	if err != nil {
		return err
	} else if v, ok := d.GetOkExists("end_time"); !tpgresource.IsEmptyValue(reflect.ValueOf(v)) && (ok || !reflect.DeepEqual(v, endTimeProp)) {
		obj["endTime"] = endTimeProp
	}
	maxRunCountProp, err := expandVertexAIScheduleMaxRunCount(d.Get("max_run_count"), d, config)
	if err != nil {
		return err
	} else if v, ok := d.GetOkExists("max_run_count"); !tpgresource.IsEmptyValue(reflect.ValueOf(v)) && (ok || !reflect.DeepEqual(v, maxRunCountProp)) {
		obj["maxRunCount"] = maxRunCountProp
	}
	pausedProp, err := expandVertexAISchedulePaused(d.Get("paused"), d, config)
	if err != nil {
		return err
	} else if v, ok := d.GetOkExists("paused"); !tpgresource.IsEmptyValue(reflect.ValueOf(v)) && (ok || !reflect.DeepEqual(v, pausedProp)) {
		obj["paused"] = pausedProp
	}
	catchUpProp, err := expandVertexAIScheduleCatchUp(d.Get("catch_up"), d, config)
	if err != nil {
		return err
	} else if v, ok := d.GetOkExists("catch_up"); !tpgresource.IsEmptyValue(reflect.ValueOf(v)) && (ok || !reflect.DeepEqual(v, catchUpProp)) {
		obj["catchUp"] = catchUpProp
	}
	maxConcurrentRunCountProp, err := expandVertexAIScheduleMaxConcurrentRunCount(d.Get("max_concurrent_run_count"), d, config)
	if err != nil {
		return err
	} else if v, ok := d.GetOkExists("max_concurrent_run_count"); !tpgresource.IsEmptyValue(reflect.ValueOf(v)) && (ok || !reflect.DeepEqual(v, maxConcurrentRunCountProp)) {
		obj["maxConcurrentRunCount"] = maxConcurrentRunCountProp
	}
	allowQueueingProp, err := expandVertexAIScheduleAllowQueueing(d.Get("allow_queueing"), d, config)
	if err != nil {
		return err
	} else if v, ok := d.GetOkExists("allow_queueing"); !tpgresource.IsEmptyValue(reflect.ValueOf(v)) && (ok || !reflect.DeepEqual(v, allowQueueingProp)) {
		obj["allowQueueing"] = allowQueueingProp
	}
	createPipelineJobRequestProp, err := expandVertexAIScheduleCreatePipelineJobRequest(d.Get("create_pipeline_job_request"), d, config)
	if err != nil {
		return err
	} else if v, ok := d.GetOkExists("create_pipeline_job_request"); !tpgresource.IsEmptyValue(reflect.ValueOf(v)) && (ok || !reflect.DeepEqual(v, createPipelineJobRequestProp)) {
		obj["createPipelineJobRequest"] = createPipelineJobRequestProp
	}

	obj, err = resourceVertexAIScheduleUpdateEncoder(d, meta, obj)
	if err != nil {
		return err
	}

	url, err := tpgresource.ReplaceVars(d, config, "{{VertexAIBasePath}}projects/{{project}}/locations/{{region}}/schedules/{{name}}")
	if err != nil {
		return err
	}

	log.Printf("[DEBUG] Updating Schedule %q: %#v", d.Id(), obj)

	// err == nil indicates that the billing_project value was found
	if bp, err := tpgresource.GetBillingProject(d, config); err == nil {
		billingProject = bp
	}

	res, err := transport_tpg.SendRequest(transport_tpg.SendRequestOptions{
		Config:    config,
		Method:    "PATCH",
		Project:   billingProject,
		RawURL:    url,
		UserAgent: userAgent,
		Body:      obj,
		Timeout:   d.Timeout(schema.TimeoutUpdate),
	})

	if err != nil {
		return fmt.Errorf("Error updating Schedule %q: %s", d.Id(), err)
	} else {
		log.Printf("[DEBUG] Finished updating Schedule %q: %#v", d.Id(), res)
	}

	if d.HasChange("paused") {
		endpoint := "resume" // Default to enabled
		logSuccessMsg := "Job state has been set to ACTIVE"
		reqBody := make(map[string]interface{})
		if paused, pausedOk := d.GetOk("paused"); pausedOk {
			if paused.(bool) {
				endpoint = "pause"
				logSuccessMsg = "Job state has been set to PAUSED"
			}
		} else if catchUp, catchUpOk := d.GetOk("catchUp"); catchUpOk && catchUp.(bool) {
			reqBody["catchUp"] = catchUp
		}

		linkTmpl := fmt.Sprintf("{{VertexAIBasePath}}projects/{{project}}/locations/{{region}}/schedules/{{name}}:%s", endpoint)
		url, err = tpgresource.ReplaceVars(d, config, linkTmpl)
		if err != nil {
			return err
		}
		_, err = transport_tpg.SendRequest(transport_tpg.SendRequestOptions{
			Config:    config,
			Method:    "POST",
			Project:   billingProject,
			RawURL:    url,
			UserAgent: userAgent,
			Body:      reqBody,
			Timeout:   d.Timeout(schema.TimeoutUpdate),
		})
		if err != nil {
			return fmt.Errorf("Error setting Cloud Scheduler Job status: %s", err)
		}

		log.Printf("[DEBUG] Finished updating Job %q status: %s", d.Id(), logSuccessMsg)
	}
	return resourceVertexAIScheduleRead(d, meta)
}

func resourceVertexAIScheduleDelete(d *schema.ResourceData, meta interface{}) error {
	config := meta.(*transport_tpg.Config)
	userAgent, err := tpgresource.GenerateUserAgentString(d, config.UserAgent)
	if err != nil {
		return err
	}

	billingProject := ""

	project, err := tpgresource.GetProject(d, config)
	if err != nil {
		return fmt.Errorf("Error fetching project for Schedule: %s", err)
	}
	billingProject = project

	url, err := tpgresource.ReplaceVars(d, config, "{{VertexAIBasePath}}projects/{{project}}/locations/{{region}}/schedules/{{name}}")
	if err != nil {
		return err
	}

	var obj map[string]interface{}
	log.Printf("[DEBUG] Deleting Schedule %q", d.Id())

	// err == nil indicates that the billing_project value was found
	if bp, err := tpgresource.GetBillingProject(d, config); err == nil {
		billingProject = bp
	}

	res, err := transport_tpg.SendRequest(transport_tpg.SendRequestOptions{
		Config:    config,
		Method:    "DELETE",
		Project:   billingProject,
		RawURL:    url,
		UserAgent: userAgent,
		Body:      obj,
		Timeout:   d.Timeout(schema.TimeoutDelete),
	})
	if err != nil {
		return transport_tpg.HandleNotFoundError(err, d, "Schedule")
	}

	log.Printf("[DEBUG] Finished deleting Schedule %q: %#v", d.Id(), res)
	return nil
}

func resourceVertexAIScheduleImport(d *schema.ResourceData, meta interface{}) ([]*schema.ResourceData, error) {
	config := meta.(*transport_tpg.Config)
	if err := tpgresource.ParseImportId([]string{
		"projects/(?P<project>[^/]+)/locations/(?P<region>[^/]+)/schedules/(?P<name>[^/]+)",
		"(?P<project>[^/]+)/(?P<region>[^/]+)/(?P<name>[^/]+)",
		"(?P<region>[^/]+)/(?P<name>[^/]+)",
		"(?P<name>[^/]+)",
	}, d, config); err != nil {
		return nil, err
	}

	// Replace import id for the resource id
	id, err := tpgresource.ReplaceVars(d, config, "projects/{{project}}/locations/{{region}}/schedules/{{name}}")
	if err != nil {
		return nil, fmt.Errorf("Error constructing id: %s", err)
	}
	d.SetId(id)

	return []*schema.ResourceData{d}, nil
}

func flattenVertexAIScheduleName(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenVertexAIScheduleDisplayName(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenVertexAIScheduleCron(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenVertexAIScheduleStartTime(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenVertexAIScheduleEndTime(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenVertexAIScheduleMaxRunCount(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenVertexAIScheduleState(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenVertexAISchedulePaused(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	state := d.Get("state")
	if state == "PAUSED" {
		return true
	}
	if state == "ACTIVE" {
		return false
	}
	return false // Job has an error state that's not paused or active
}

func flattenVertexAIScheduleCatchUp(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenVertexAIScheduleMaxConcurrentRunCount(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	// Handles the string fixed64 format
	if strVal, ok := v.(string); ok {
		if intVal, err := tpgresource.StringToFixed64(strVal); err == nil {
			return intVal
		}
	}

	// number values are represented as float64
	if floatVal, ok := v.(float64); ok {
		intVal := int(floatVal)
		return intVal
	}

	return v // let terraform core handle it otherwise
}

func flattenVertexAIScheduleAllowQueueing(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenVertexAIScheduleCreatePipelineJobRequest(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	if v == nil {
		return nil
	}
	original := v.(map[string]interface{})
	if len(original) == 0 {
		return nil
	}
	transformed := make(map[string]interface{})
	transformed["parent"] =
		flattenVertexAIScheduleCreatePipelineJobRequestParent(original["parent"], d, config)
	transformed["pipeline_job"] =
		flattenVertexAIScheduleCreatePipelineJobRequestPipelineJob(original["pipelineJob"], d, config)
	return []interface{}{transformed}
}
func flattenVertexAIScheduleCreatePipelineJobRequestParent(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenVertexAIScheduleCreatePipelineJobRequestPipelineJob(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	if v == nil {
		return nil
	}
	original := v.(map[string]interface{})
	if len(original) == 0 {
		return nil
	}
	transformed := make(map[string]interface{})
	transformed["display_name"] =
		flattenVertexAIScheduleCreatePipelineJobRequestPipelineJobDisplayName(original["displayName"], d, config)
	transformed["pipeline_spec"] =
		flattenVertexAIScheduleCreatePipelineJobRequestPipelineJobPipelineSpec(original["pipelineSpec"], d, config)
	transformed["labels"] =
		flattenVertexAIScheduleCreatePipelineJobRequestPipelineJobLabels(original["labels"], d, config)
	transformed["runtime_config"] =
		flattenVertexAIScheduleCreatePipelineJobRequestPipelineJobRuntimeConfig(original["runtimeConfig"], d, config)
	transformed["service_account"] =
		flattenVertexAIScheduleCreatePipelineJobRequestPipelineJobServiceAccount(original["serviceAccount"], d, config)
	transformed["network"] =
		flattenVertexAIScheduleCreatePipelineJobRequestPipelineJobNetwork(original["network"], d, config)
	transformed["template_uri"] =
		flattenVertexAIScheduleCreatePipelineJobRequestPipelineJobTemplateUri(original["templateUri"], d, config)
	return []interface{}{transformed}
}
func flattenVertexAIScheduleCreatePipelineJobRequestPipelineJobDisplayName(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenVertexAIScheduleCreatePipelineJobRequestPipelineJobPipelineSpec(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	if v == nil {
		return nil
	}
	b, err := json.Marshal(v)
	if err != nil {
		// TODO: return error once https://github.com/GoogleCloudPlatform/magic-modules/issues/3257 is fixed.
		log.Printf("[ERROR] failed to marshal schema to JSON: %v", err)
	}
	return string(b)
}

func flattenVertexAIScheduleCreatePipelineJobRequestPipelineJobLabels(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenVertexAIScheduleCreatePipelineJobRequestPipelineJobRuntimeConfig(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	if v == nil {
		return nil
	}
	original := v.(map[string]interface{})
	if len(original) == 0 {
		return nil
	}
	transformed := make(map[string]interface{})
	transformed["parameters"] =
		flattenVertexAIScheduleCreatePipelineJobRequestPipelineJobRuntimeConfigParameters(original["parameters"], d, config)
	transformed["gcs_output_directory"] =
		flattenVertexAIScheduleCreatePipelineJobRequestPipelineJobRuntimeConfigGcsOutputDirectory(original["gcsOutputDirectory"], d, config)
	transformed["parameter_values"] =
		flattenVertexAIScheduleCreatePipelineJobRequestPipelineJobRuntimeConfigParameterValues(original["parameterValues"], d, config)
	transformed["failure_policy"] =
		flattenVertexAIScheduleCreatePipelineJobRequestPipelineJobRuntimeConfigFailurePolicy(original["failurePolicy"], d, config)
	transformed["input_artifacts"] =
		flattenVertexAIScheduleCreatePipelineJobRequestPipelineJobRuntimeConfigInputArtifacts(original["inputArtifacts"], d, config)
	return []interface{}{transformed}
}
func flattenVertexAIScheduleCreatePipelineJobRequestPipelineJobRuntimeConfigParameters(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	if v == nil {
		return nil
	}
	b, err := json.Marshal(v)
	if err != nil {
		// TODO: return error once https://github.com/GoogleCloudPlatform/magic-modules/issues/3257 is fixed.
		log.Printf("[ERROR] failed to marshal schema to JSON: %v", err)
	}
	return string(b)
}

func flattenVertexAIScheduleCreatePipelineJobRequestPipelineJobRuntimeConfigGcsOutputDirectory(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenVertexAIScheduleCreatePipelineJobRequestPipelineJobRuntimeConfigParameterValues(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	if v == nil {
		return nil
	}
	b, err := json.Marshal(v)
	if err != nil {
		// TODO: return error once https://github.com/GoogleCloudPlatform/magic-modules/issues/3257 is fixed.
		log.Printf("[ERROR] failed to marshal schema to JSON: %v", err)
	}
	return string(b)
}

func flattenVertexAIScheduleCreatePipelineJobRequestPipelineJobRuntimeConfigFailurePolicy(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenVertexAIScheduleCreatePipelineJobRequestPipelineJobRuntimeConfigInputArtifacts(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenVertexAIScheduleCreatePipelineJobRequestPipelineJobServiceAccount(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenVertexAIScheduleCreatePipelineJobRequestPipelineJobNetwork(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenVertexAIScheduleCreatePipelineJobRequestPipelineJobTemplateUri(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func expandVertexAIScheduleName(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (interface{}, error) {
	return v, nil
}

func expandVertexAIScheduleDisplayName(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (interface{}, error) {
	return v, nil
}

func expandVertexAIScheduleCron(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (interface{}, error) {
	return v, nil
}

func expandVertexAIScheduleStartTime(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (interface{}, error) {
	return v, nil
}

func expandVertexAIScheduleEndTime(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (interface{}, error) {
	return v, nil
}

func expandVertexAIScheduleMaxRunCount(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (interface{}, error) {
	return v, nil
}

func expandVertexAISchedulePaused(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (interface{}, error) {
	return v, nil
}

func expandVertexAIScheduleCatchUp(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (interface{}, error) {
	return v, nil
}

func expandVertexAIScheduleMaxConcurrentRunCount(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (interface{}, error) {
	return v, nil
}

func expandVertexAIScheduleAllowQueueing(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (interface{}, error) {
	return v, nil
}

func expandVertexAIScheduleCreatePipelineJobRequest(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (interface{}, error) {
	l := v.([]interface{})
	if len(l) == 0 || l[0] == nil {
		return nil, nil
	}
	raw := l[0]
	original := raw.(map[string]interface{})
	transformed := make(map[string]interface{})

	transformedParent, err := expandVertexAIScheduleCreatePipelineJobRequestParent(original["parent"], d, config)
	if err != nil {
		return nil, err
	} else if val := reflect.ValueOf(transformedParent); val.IsValid() && !tpgresource.IsEmptyValue(val) {
		transformed["parent"] = transformedParent
	}

	transformedPipelineJob, err := expandVertexAIScheduleCreatePipelineJobRequestPipelineJob(original["pipeline_job"], d, config)
	if err != nil {
		return nil, err
	} else if val := reflect.ValueOf(transformedPipelineJob); val.IsValid() && !tpgresource.IsEmptyValue(val) {
		transformed["pipelineJob"] = transformedPipelineJob
	}

	return transformed, nil
}

func expandVertexAIScheduleCreatePipelineJobRequestParent(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (interface{}, error) {
	return v, nil
}

func expandVertexAIScheduleCreatePipelineJobRequestPipelineJob(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (interface{}, error) {
	l := v.([]interface{})
	if len(l) == 0 || l[0] == nil {
		return nil, nil
	}
	raw := l[0]
	original := raw.(map[string]interface{})
	transformed := make(map[string]interface{})

	transformedDisplayName, err := expandVertexAIScheduleCreatePipelineJobRequestPipelineJobDisplayName(original["display_name"], d, config)
	if err != nil {
		return nil, err
	} else if val := reflect.ValueOf(transformedDisplayName); val.IsValid() && !tpgresource.IsEmptyValue(val) {
		transformed["displayName"] = transformedDisplayName
	}

	transformedPipelineSpec, err := expandVertexAIScheduleCreatePipelineJobRequestPipelineJobPipelineSpec(original["pipeline_spec"], d, config)
	if err != nil {
		return nil, err
	} else if val := reflect.ValueOf(transformedPipelineSpec); val.IsValid() && !tpgresource.IsEmptyValue(val) {
		transformed["pipelineSpec"] = transformedPipelineSpec
	}

	transformedLabels, err := expandVertexAIScheduleCreatePipelineJobRequestPipelineJobLabels(original["labels"], d, config)
	if err != nil {
		return nil, err
	} else if val := reflect.ValueOf(transformedLabels); val.IsValid() && !tpgresource.IsEmptyValue(val) {
		transformed["labels"] = transformedLabels
	}

	transformedRuntimeConfig, err := expandVertexAIScheduleCreatePipelineJobRequestPipelineJobRuntimeConfig(original["runtime_config"], d, config)
	if err != nil {
		return nil, err
	} else if val := reflect.ValueOf(transformedRuntimeConfig); val.IsValid() && !tpgresource.IsEmptyValue(val) {
		transformed["runtimeConfig"] = transformedRuntimeConfig
	}

	transformedServiceAccount, err := expandVertexAIScheduleCreatePipelineJobRequestPipelineJobServiceAccount(original["service_account"], d, config)
	if err != nil {
		return nil, err
	} else if val := reflect.ValueOf(transformedServiceAccount); val.IsValid() && !tpgresource.IsEmptyValue(val) {
		transformed["serviceAccount"] = transformedServiceAccount
	}

	transformedNetwork, err := expandVertexAIScheduleCreatePipelineJobRequestPipelineJobNetwork(original["network"], d, config)
	if err != nil {
		return nil, err
	} else if val := reflect.ValueOf(transformedNetwork); val.IsValid() && !tpgresource.IsEmptyValue(val) {
		transformed["network"] = transformedNetwork
	}

	transformedTemplateUri, err := expandVertexAIScheduleCreatePipelineJobRequestPipelineJobTemplateUri(original["template_uri"], d, config)
	if err != nil {
		return nil, err
	} else if val := reflect.ValueOf(transformedTemplateUri); val.IsValid() && !tpgresource.IsEmptyValue(val) {
		transformed["templateUri"] = transformedTemplateUri
	}

	return transformed, nil
}

func expandVertexAIScheduleCreatePipelineJobRequestPipelineJobDisplayName(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (interface{}, error) {
	return v, nil
}

func expandVertexAIScheduleCreatePipelineJobRequestPipelineJobPipelineSpec(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (interface{}, error) {
	b := []byte(v.(string))
	if len(b) == 0 {
		return nil, nil
	}
	m := make(map[string]interface{})
	if err := json.Unmarshal(b, &m); err != nil {
		return nil, err
	}
	return m, nil
}

func expandVertexAIScheduleCreatePipelineJobRequestPipelineJobLabels(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (map[string]string, error) {
	if v == nil {
		return map[string]string{}, nil
	}
	m := make(map[string]string)
	for k, val := range v.(map[string]interface{}) {
		m[k] = val.(string)
	}
	return m, nil
}

func expandVertexAIScheduleCreatePipelineJobRequestPipelineJobRuntimeConfig(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (interface{}, error) {
	l := v.([]interface{})
	if len(l) == 0 || l[0] == nil {
		return nil, nil
	}
	raw := l[0]
	original := raw.(map[string]interface{})
	transformed := make(map[string]interface{})

	transformedParameters, err := expandVertexAIScheduleCreatePipelineJobRequestPipelineJobRuntimeConfigParameters(original["parameters"], d, config)
	if err != nil {
		return nil, err
	} else if val := reflect.ValueOf(transformedParameters); val.IsValid() && !tpgresource.IsEmptyValue(val) {
		transformed["parameters"] = transformedParameters
	}

	transformedGcsOutputDirectory, err := expandVertexAIScheduleCreatePipelineJobRequestPipelineJobRuntimeConfigGcsOutputDirectory(original["gcs_output_directory"], d, config)
	if err != nil {
		return nil, err
	} else if val := reflect.ValueOf(transformedGcsOutputDirectory); val.IsValid() && !tpgresource.IsEmptyValue(val) {
		transformed["gcsOutputDirectory"] = transformedGcsOutputDirectory
	}

	transformedParameterValues, err := expandVertexAIScheduleCreatePipelineJobRequestPipelineJobRuntimeConfigParameterValues(original["parameter_values"], d, config)
	if err != nil {
		return nil, err
	} else if val := reflect.ValueOf(transformedParameterValues); val.IsValid() && !tpgresource.IsEmptyValue(val) {
		transformed["parameterValues"] = transformedParameterValues
	}

	transformedFailurePolicy, err := expandVertexAIScheduleCreatePipelineJobRequestPipelineJobRuntimeConfigFailurePolicy(original["failure_policy"], d, config)
	if err != nil {
		return nil, err
	} else if val := reflect.ValueOf(transformedFailurePolicy); val.IsValid() && !tpgresource.IsEmptyValue(val) {
		transformed["failurePolicy"] = transformedFailurePolicy
	}

	transformedInputArtifacts, err := expandVertexAIScheduleCreatePipelineJobRequestPipelineJobRuntimeConfigInputArtifacts(original["input_artifacts"], d, config)
	if err != nil {
		return nil, err
	} else if val := reflect.ValueOf(transformedInputArtifacts); val.IsValid() && !tpgresource.IsEmptyValue(val) {
		transformed["inputArtifacts"] = transformedInputArtifacts
	}

	return transformed, nil
}

func expandVertexAIScheduleCreatePipelineJobRequestPipelineJobRuntimeConfigParameters(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (interface{}, error) {
	b := []byte(v.(string))
	if len(b) == 0 {
		return nil, nil
	}
	m := make(map[string]interface{})
	if err := json.Unmarshal(b, &m); err != nil {
		return nil, err
	}
	return m, nil
}

func expandVertexAIScheduleCreatePipelineJobRequestPipelineJobRuntimeConfigGcsOutputDirectory(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (interface{}, error) {
	return v, nil
}

func expandVertexAIScheduleCreatePipelineJobRequestPipelineJobRuntimeConfigParameterValues(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (interface{}, error) {
	b := []byte(v.(string))
	if len(b) == 0 {
		return nil, nil
	}
	m := make(map[string]interface{})
	if err := json.Unmarshal(b, &m); err != nil {
		return nil, err
	}
	return m, nil
}

func expandVertexAIScheduleCreatePipelineJobRequestPipelineJobRuntimeConfigFailurePolicy(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (interface{}, error) {
	return v, nil
}

func expandVertexAIScheduleCreatePipelineJobRequestPipelineJobRuntimeConfigInputArtifacts(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (map[string]string, error) {
	if v == nil {
		return map[string]string{}, nil
	}
	m := make(map[string]string)
	for k, val := range v.(map[string]interface{}) {
		m[k] = val.(string)
	}
	return m, nil
}

func expandVertexAIScheduleCreatePipelineJobRequestPipelineJobServiceAccount(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (interface{}, error) {
	return v, nil
}

func expandVertexAIScheduleCreatePipelineJobRequestPipelineJobNetwork(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (interface{}, error) {
	return v, nil
}

func expandVertexAIScheduleCreatePipelineJobRequestPipelineJobTemplateUri(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (interface{}, error) {
	return v, nil
}

func resourceVertexAIScheduleEncoder(d *schema.ResourceData, meta interface{}, obj map[string]interface{}) (map[string]interface{}, error) {
	delete(obj, "paused") // Field doesn't exist in API
	return obj, nil
}

func resourceVertexAIScheduleUpdateEncoder(d *schema.ResourceData, meta interface{}, obj map[string]interface{}) (map[string]interface{}, error) {
	delete(obj, "paused") // Field doesn't exist in API
	return obj, nil
}
